"""
===========================
Plots with different scales
===========================

Demonstrate how to do two plots on the same axes with different left and
right scales.

The trick is to use *two different axes* that share the same *x* axis.
You can use separate `matplotlib.ticker` formatters and locators as
desired since the two axes are independent.

Such axes are generated by calling the `Axes.twinx` method.  Likewise,
`Axes.twiny` is available to generate axes that share a *y* axis but
have different top and bottom scales.

The twinx and twiny methods are also exposed as pyplot functions.

"""
from __future__ import absolute_import, division, print_function

import cPickle as pickle
import collections
import numpy as np
import sklearn.metrics

import matplotlib as mpl

mpl.use("pgf")
pgf_with_rc_fonts = {
    "font.family": "serif",
    "font.serif": [],  # use latex default serif font
    "font.sans-serif": ["DejaVu Sans"],  # use a specific sans-serif font
    "font.size": 25
}
mpl.rcParams.update(pgf_with_rc_fonts)
# matplotlib.use('Agg')
import matplotlib.pyplot as plt


def _fix_prediction_id_to_ground_truth_id(prediction_id):
    id_splits = prediction_id.split('_')
    id_splits[-3] = str(int(id_splits[-3]) - 1)
    return '_'.join(id_splits)


with open('event_recall.pkl') as f:
    event_recall_stats = pickle.load(f)

dataset_to_legend = {
    'elephant': 'T5',
    'raft': 'T4',
    'okutama': 'T1',
    'stanford': 'T3'
}
cmap = plt.cm.rainbow(np.linspace(0, 1, len(dataset_to_legend.keys())))
color = iter(cmap)

fig, ax1 = plt.subplots()
for dataset_name in ['okutama', 'stanford', 'raft', 'elephant']:
    stats = event_recall_stats[dataset_name]
    print('ploting {}'.format(dataset_name))
    track_to_fire_thresholds = stats['track_to_fire_thresholds']
    track_to_min_fire_thresholds = {
        k: max(v)
        for k, v in track_to_fire_thresholds.items()
    }
    fire_thresholds = track_to_min_fire_thresholds.values()
    fire_thresholds = np.append(fire_thresholds, 0)
    fire_thresholds = sorted(fire_thresholds, reverse=True)

    event_recall = np.array(range(
        1,
        len(fire_thresholds) + 1)) / len(fire_thresholds)
    c_color = next(color)
    ax1.plot(
        fire_thresholds,
        event_recall,
        c=c_color,
        label=dataset_to_legend[dataset_name])
    # ax1.plot(
    #     fire_thresholds, event_recall, c=c_color, marker='s', markersize=2)

ax1.set_xlabel('Cutoff Probability')
# Make the y-axis label, ticks and tick labels match the line color.
ax1.set_ylabel('Event Recall')
ax1.tick_params('y')
ax1.set_xlim([0, 1.05])
ax1.set_ylim([0, 1.05])
plt.legend(loc='best', fontsize=13)
plt.gca().invert_xaxis()
plt.savefig('fig-event-recall-vs-threshold.pdf', bbox_inches='tight')

print('finished plotting event recall vs threshold')

for dataset_name, stats in event_recall_stats.iteritems():
    plt.clf()
    fig, ax1 = plt.subplots()
    cmap = plt.cm.rainbow(np.linspace(0, 1, 4))
    color = iter(cmap)

    print('ploting {}'.format(dataset_name))
    predictions_thresholds = stats['predictions_thresholds']
    increasing_threshold_predictions = collections.OrderedDict(
        sorted(predictions_thresholds.items(), key=lambda t: t[1]))
    assert len(increasing_threshold_predictions) == len(predictions_thresholds)
    ground_truths = stats['ground_truth']
    y_true, y_score = [], []
    positive_num, negative_num = 0, 0
    for tile_id, threshold in increasing_threshold_predictions.iteritems():
        if ground_truths[_fix_prediction_id_to_ground_truth_id(tile_id)]:
            positive_num += 1
        else:
            negative_num += 1
        y_true.append(
            ground_truths[_fix_prediction_id_to_ground_truth_id(tile_id)])
        y_score.append(threshold)
    print('positive num: {}, negative num: {}'.format(positive_num,
                                                      negative_num))
    fpr, tpr, roc_threshold = sklearn.metrics.roc_curve(y_true, y_score)
    fp = fpr * negative_num
    tp = tpr * positive_num
    fn = (1 - tpr) * positive_num
    tn = (1 - fpr) * negative_num

    total_num = positive_num + negative_num
    fp = fp / total_num
    tp = tp / total_num
    fn = fn / total_num
    tn = tn / total_num

    ax1.fill_between(
        roc_threshold,
        tp,
        0,
        where=tp >= 0,
        facecolor=next(color),
        alpha=0.5,
        interpolate=True,
        label='True Positives')
    ax1.fill_between(
        roc_threshold,
        fp + tp,
        tp,
        where=fp + tp > tp,
        facecolor=next(color),
        alpha=0.5,
        interpolate=True,
        label='False Positives')
    ax1.fill_between(
        roc_threshold,
        fp + tp + fn,
        fp + tp,
        where=fp + tp + fn > fp + tp,
        facecolor=next(color),
        alpha=0.5,
        interpolate=True,
        label='False Negatives')
    ax1.fill_between(
        roc_threshold,
        fp + tp + fn + tn,
        fp + tp + fn,
        where=fp + tp + fn + tn > fp + tp + fn,
        facecolor=next(color),
        alpha=0.5,
        interpolate=True,
        label='True Negatives')
    ax1.set_xlabel('Cutoff Probability')
    # Make the y-axis label, ticks and tick labels match the line color.
    ax1.set_ylabel('Percentage of Frames')
    ax1.set_xlim([0, 1.05])
    ax1.set_ylim([0, 1.05])
    plt.legend(loc='best', fontsize=22)
    plt.gca().invert_xaxis()
    plt.savefig(
        'fig-{}-bw-vs-threshold.pdf'.format(dataset_name), bbox_inches='tight')

print('plot tp, fp vs event recall')
for dataset_name, stats in event_recall_stats.iteritems():
    plt.clf()
    fig, ax1 = plt.subplots()
    cmap = plt.cm.rainbow(np.linspace(0, 1, 3))
    color = iter(cmap)

    print('ploting {}'.format(dataset_name))
    predictions_thresholds = stats['predictions_thresholds']
    increasing_threshold_predictions = collections.OrderedDict(
        sorted(predictions_thresholds.items(), key=lambda t: t[1]))
    assert len(increasing_threshold_predictions) == len(predictions_thresholds)
    ground_truths = stats['ground_truth']
    y_true, y_score = [], []
    positive_num, negative_num = 0, 0

    tp_threshold, fp_threshold = [], []
    for threshold in fire_thresholds:
        tp, fp = 0, 0
        for tile_id, pred_proba in increasing_threshold_predictions.iteritems(
        ):
            if pred_proba > threshold:
                if ground_truths[_fix_prediction_id_to_ground_truth_id(
                        tile_id)]:
                    tp += 1
                else:
                    fp += 1
        tp_threshold.append(tp)
        fp_threshold.append(fp)
    tp_threshold = np.array(tp_threshold) / len(
        increasing_threshold_predictions)
    fp_threshold = np.array(fp_threshold) / len(
        increasing_threshold_predictions)
    ax1.fill_between(
        event_recall,
        tp_threshold,
        0,
        where=tp_threshold >= 0,
        facecolor=next(color),
        alpha=0.5,
        interpolate=True,
        label='True Positives')
    ax1.fill_between(
        event_recall,
        fp_threshold + tp_threshold,
        tp_threshold,
        where=fp_threshold + tp_threshold > tp_threshold,
        facecolor=next(color),
        alpha=0.5,
        interpolate=True,
        label='False Positives')
    ax1.fill_between(
        event_recall,
        1,
        fp_threshold + tp_threshold,
        where=1 > fp_threshold + tp_threshold,
        facecolor=next(color),
        alpha=0.5,
        interpolate=True,
        label='Not Transmitted')
    ax1.set_xlabel('Event Recall')
    # Make the y-axis label, ticks and tick labels match the line color.
    ax1.set_ylabel('Percentage of Frames')
    ax1.set_xlim([0, 1.05])
    ax1.set_ylim([0, 1.05])
    plt.legend(
        loc='upper center',
        bbox_to_anchor=(0.5, 1.3),
        ncol=2,
        fancybox=True,
        fontsize=20)
    plt.savefig(
        'fig-{}-precision-vs-event-recall.pdf'.format(dataset_name),
        bbox_inches='tight')


def get_video_tile_to_uniq_track_id(base_dir, dataset):
    load_annotation_func = annotation_stats.dataset[dataset][
        'annotation_func']
    labels = annotation_stats.dataset[dataset]['labels']
    annotation_dir = os.path.join(base_dir, datasets[dataset][0])
    annotations = load_annotation_func(annotation_dir)
    test_video_ids = annotation_stats.dataset[dataset]['test']
    annotations = annotations[annotations['videoid'].isin(test_video_ids)]
    annotations = annotation.filter_annotation_by_label(
        annotations, labels=labels)
    video_id_to_original_resolution = annotation_stats.dataset[dataset][
        'video_id_to_original_resolution']
    # make track ID unique across different videos
    track_annotations_grp = annotation.group_annotation_by_unique_track_ids(
        annotations)
    video_tile_to_uniq_track_id = collections.defaultdict(list)

    for track_id, track_annotations in track_annotations_grp:
        videoid = track_annotations.iloc[0]['videoid']
        image_resolution = video_id_to_original_resolution[videoid]

        for _, row in track_annotations.iterrows():
            bbox = _clamp_bbox(image_resolution,
                               (row['xmin'], row['ymin'], row['xmax'], row['ymax']))
            tile_coords = _get_tile_coords_from_bbox(image_resolution, bbox,
                                                     long_edge_ratio=0.5, short_edge_ratio=1)
            for tile_coord in tile_coords:
                tile_id = _combine_imageid(row['videoid'], row['frameid'], *tile_coord)
                video_tile_to_uniq_track_id[tile_id].extend(track_id)

    return video_tile_to_uniq_track_id


def get_video_frame_to_uniq_track_id(base_dir, dataset):
    load_annotation_func = annotation_stats.dataset[dataset][
        'annotation_func']
    labels = annotation_stats.dataset[dataset]['labels']
    annotation_dir = os.path.join(base_dir, datasets[dataset][0])
    annotations = load_annotation_func(annotation_dir)
    test_video_ids = annotation_stats.dataset[dataset]['test']
    annotations = annotations[annotations['videoid'].isin(test_video_ids)]
    annotations = annotation.filter_annotation_by_label(
        annotations, labels=labels)
    # make track ID unique across different videos
    track_annotations_grp = annotation.group_annotation_by_unique_track_ids(
        annotations)
    video_frame_to_uniq_track_id = collections.defaultdict(list)
    for track_id, track_annotations in track_annotations_grp:
        for _, row in track_annotations.iterrows():
            video_id = row['videoid']
            frame_id = row['frameid']
            video_frame_to_uniq_track_id[(video_id, frame_id)].append(track_id)
    all_unique_trakc_ids = set(track_annotations_grp.groups.keys())
    print("Parsed annotations. Found {} unique track IDs in {}.".format(
        len(all_unique_trakc_ids), ','.join(all_unique_trakc_ids)))
    return all_unique_trakc_ids, video_frame_to_uniq_track_id

